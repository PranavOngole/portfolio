# Sai Pranav Ongole

**Data Analyst @ Capital One** Â· Austin, TX Â· US Citizen

I build data systems that scale. SQL, Python, Snowflake, Databricks â€” I've used them on real problems at real companies processing tens of millions of records daily. I also build things with AI that most data teams haven't figured out yet.

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Sai_Pranav_Ongole-0077B5?style=flat&logo=linkedin)](https://www.linkedin.com/in/pranavo/)
[![Email](https://img.shields.io/badge/Email-pranavongole@gmail.com-D14836?style=flat&logo=gmail)](mailto:pranavongole@gmail.com)
---

## ğŸ› ï¸ Stack

```python
# Day job
Analytics & Querying: SQL (Snowflake, MySQL), Python (pandas), Exploratory Data Analysis, KPI Analysis, Metric
Definitions
Data Modeling & Platforms: Data Modeling (fact & dimension tables), Data Warehousing Concepts, Snowflake,
Databricks, AWS S3, ETL Pipelines
Data Dictionaries
BI & Visualization: PowerBI, Tableau, Quicksight, DOMO, Executive & Stakeholder Dashboards
Business & Foundations: A/B Testing, Financial & Operational Analytics, Machine Learning (foundational),
Operations Research, Data Structures & Algorithms, Version Control (Git)

# Side projects
ai_agents  = ["Claude Code", "Anthropic API", "ChatGPT"]
data       = ["Python", "pandas", "DuckDB", "Plotly"]
workflow   = ["ETL Automation", "AI Agent Pipelines", "LLM Orchestration"]
```
---

## ğŸ’¼ Experience

**Capital One** Â· Data Analyst *(Oct 2025 â€“ Present)*  
â€¢ Supported pricing compliance and risk monitoring by analyzing millions of daily transactions, helping ensure interest
rate caps and grandfathered terms were correctly applied across 60M+ customer accounts.  
â€¢ Built SQL- and Python-based validation checks to compare internal transaction processing outputs against third-party
vendor data, catching discrepancies before vendor systems were fully sunset.  
â€¢ Developed automated monitoring and alerting workflows in Snowflake and Databricks to flag data quality issues early,
reducing downstream reporting errors and manual investigations.  
â€¢ Partnered with engineering and risk teams to migrate 100+ production workflows to Unity Catalog, improving data
governance, access control, and auditability.  
â€¢ Designed scalable analytical tables and pipelines supporting compliance dashboards and ad-hoc analysis, processing
90M+ records daily with high reliability.  

**Stellantis** Â· Data Analytics Engineer *(Jun 2024 â€“ Jan 2025)*  
â€¢ Built Power BI dashboards to track testing and program KPIs across 10+ vehicle programs, reducing manual statusreporting time by 12%.
â€¢ Implemented automated data quality checks on battery testing datasets using SQL and Python, reducingdownstream data issues and rework by 25%.
â€¢ Partnered with operations and product teams to define and roll out data quality standards adopted across multiple programs.
â€¢ Performed root-cause analysis on recurring data anomalies, helping teams identify upstream failures and reduce repeat data defects.
**Archaea Energy** Â· Data Quality Analyst *(Jul 2022 â€“ Jun 2024)*  
â€¢ Owned data quality processes for operational datasets across 45+ biogas facilities, supporting daily analytics and operational decision-making.
â€¢ Built Python-based validation logic and monitoring dashboards with statistical bounds, reducing manual data checks by 50%.
â€¢ Partnered with operations teams to investigate data issues, document root causes, and update pipelines as systems evolved.
â€¢ Created and maintained centralized documentation and data dictionaries, reducing onboarding time and recurring data definition questions.

**Gillig** Â· Data Analyst, Vehicle Test Engineering *(Mar 2021 â€“ Jul 2022)*  
â€¢ Analyzed vehicle test data contributing to a 9% improvement in eBus acceleration performance. 
â€¢ Automated recurring workflows saving ~20 hours/week across the team.

---

## ğŸ“ Education

**M.S. Business Analytics** â€” Rutgers Universityâ€“Camden *(Dec 2024)*  
**B.S. Mechanical Engineering** â€” Wayne State University *(Aug 2020)*

---

## ğŸ¤– What I'm Building: POV (Pranav Ongole's Vision)

A series of AI-agent-driven data platforms. Each project proves one thesis: **a single AI agent can replace days of manual data engineering work.**

| Project | What It Does | Status |
|---------|-------------|--------|
| **[Project-00: US Immigration Data Platform](https://github.com/PranavOngole/Project-00)** | AI agent ingests 27 years of State Dept visa data, cleans 28 inconsistent Excel sheets, loads into DuckDB, and serves an interactive dashboard â€” autonomously | ğŸŸ¢ Active |
| **Project-01** | Will be revealed soon | ğŸ”œ Coming |
| **Project-02** | Will be revealed soon | ğŸ”œ Coming |

### What Project-00 proved in one session:
```
âœ“ Merged 28 Excel sheets (FY1997â€“2024) with inconsistent column schemas
âœ“ Standardized 96 visa types across 27 years of naming convention changes
âœ“ Loaded 5,564 rows Ã— 98 columns into DuckDB
âœ“ Built interactive Plotly dashboard with filters
âœ“ Manual estimate: 2 days â†’ Actual: 2 hours

Key insight the agent found: India issued 1.37M visas in FY2024.
150,647 H-1Bs â€” nearly 5x China's 31,735.
```



---

## ğŸ“¬ Let's Connect

Building with AI agents Â· Data engineering Â· LLM orchestration Â· Always down to talk data

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Sai_Pranav_Ongole-0077B5?style=flat&logo=linkedin)](https://www.linkedin.com/in/pranavo/)
[![GitHub](https://img.shields.io/badge/GitHub-PranavOngole-181717?style=flat&logo=github)](https://github.com/PranavOngole)
[![Email](https://img.shields.io/badge/Email-pranavongole@gmail.com-D14836?style=flat&logo=gmail)](mailto:pranavongole@gmail.com)

---

*Open to Senior Data Analyst, Analytics Engineer, and AI/Data consulting conversations.*
